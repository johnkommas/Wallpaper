import imaplib
import email
from email.header import decode_header
import pandas as pd
from dotenv import load_dotenv
import os
import re
from tqdm import tqdm
from mikrotik import data_analysis
from routeros_api import connect
import routeros_api
import paramiko
from datetime import datetime

# Î ÏÎ¿Î²Î¿Î»Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ ÏƒÏ„Î·Î»ÏÎ½
pd.set_option("display.max_columns", None)

# Î‘Î½ Î¸Î­Î»ÎµÏ„Îµ ÎµÏ€Î¯ÏƒÎ·Ï‚ Î½Î± Î´ÎµÎ¯Ï„Îµ ÎºÎ±Î¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ ÏƒÎµÎ¹ÏÎ­Ï‚
pd.set_option("display.max_rows", None)

# Î“Î¹Î± Ï€Î»Î®ÏÎ· ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï… Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (ÏƒÎµ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· Ï€Î¿Ï… ÎºÏŒÎ²Î¿Î½Ï„Î±Î¹)
pd.set_option("display.max_colwidth", None)

# Î ÏÎ¿Î²Î¿Î»Î® Ï‡Ï‰ÏÎ¯Ï‚ ÏƒÏ…Î½Ï„ÏŒÎ¼ÎµÏ…ÏƒÎ· (ÏŒÏ€Ï‰Ï‚ "...")
pd.set_option("display.expand_frame_repr", False)

load_dotenv()


# Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ Gmail
def connect_to_gmail():
    try:
        # Î›Î®ÏˆÎ· Î´Î¹Î±Ï€Î¹ÏƒÏ„ÎµÏ…Ï„Î·ÏÎ¯Ï‰Î½ Î±Ï€ÏŒ Ï€ÎµÏÎ¹Î²Î±Î»Î»Î¿Î½Ï„Î¹ÎºÎ­Ï‚ Î¼ÎµÏ„Î±Î²Î»Î·Ï„Î­Ï‚
        gmail_user = os.getenv("GMAIL_USER")
        gmail_pass = os.getenv("GMAIL_PASS")

        if not gmail_user or not gmail_pass:
            raise ValueError(
                "Missing Gmail credentials (GMAIL_USER and/or GMAIL_PASS)."
            )

        # Î£ÏÎ½Î´ÎµÏƒÎ· ÏƒÏ„Î¿Î½ IMAP Server
        mail = imaplib.IMAP4_SSL("imap.gmail.com")
        mail.login(gmail_user, gmail_pass)
        # print("Connected")
        return mail
    except imaplib.IMAP4.error as e:
        print(f"Failed to connect: {e}", end="")
        return None
    except ValueError as e:
        print(f"Error: {e}", end="")
        return None


# ğŸ“¡ Who is Using the Most Bandwidth?
def get_Bandwidth_Usage(client):
    # Execute the command
    command = "/ip accounting snapshot print"
    stdin, stdout, stderr = client.exec_command(command)

    # Read and Return output
    return stdout.read().decode("utf-8")


def get_active_vpn_users(client):
    # Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÎµÎ½Ï„Î¿Î»Î®Ï‚ Î³Î¹Î± ÎµÎ½ÎµÏÎ³Î­Ï‚ PPP ÏƒÏ…Î½Î´Î­ÏƒÎµÎ¹Ï‚ (VPN)
    stdin, stdout, stderr = client.exec_command("/ppp active print terse")
    ppp_output = stdout.read().decode("utf-8")

    # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎµÎ¾ÏŒÎ´Î¿Ï… ÏƒÎµ Î»Î¯ÏƒÏ„Î±, Î³ÏÎ±Î¼Î¼Î® Î±Î½Î¬ Î³ÏÎ±Î¼Î¼Î®
    lines = ppp_output.strip().split("\n")

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î»Î¯ÏƒÏ„Î±Ï‚ Î»ÎµÎ¾Î¹ÎºÏÎ½ Î³Î¹Î± Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    data = []
    for line in lines:
        entry = {}
        # Î§ÏÏÎ¹ÏƒÎ¼Î± ÎºÎ¬Î¸Îµ Î³ÏÎ±Î¼Î¼Î®Ï‚ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ ÎºÎµÎ½ÏŒ Î´Î¹Î¬ÏƒÏ„Î·Î¼Î±
        for part in line.split():
            if "=" in part:
                key, value = part.split("=", 1)  # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ„Î¿ "="
                entry[key] = value
        data.append(entry)

    # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ DataFrame
    df = pd.DataFrame(data)
    return df


def connect_via_ssh():
    try:
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± SSH Client
        client = paramiko.SSHClient()
        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

        # Î£ÏÎ½Î´ÎµÏƒÎ·
        client.connect(
            hostname=os.getenv("MIKROTIK_HOST"),
            username=os.getenv("MIKROTIK_USER"),
            password=os.getenv("MIKROTIK_PASS"),
            port=int(os.getenv("MIKROTIK_PORT", 22)),  # Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î® port: 22
        )
    except Exception as e:
        print(f"Error connecting via SSH: {e}")
    finally:
        if client:
            VPN = get_active_vpn_users(client)
            client.close()
            return VPN



# Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î±ÏƒÏ†Î±Î»Î® Î±Ï€Î¿ÎºÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
def decode_safe(payload, encoding="utf-8"):
    try:
        # Î ÏÏÏ„Î· Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î· ÏƒÏ„Î·Î½ Ï€ÏÎ¿ÎºÎ±Î¸Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î· ÎºÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· (UTF-8)
        return payload.decode(encoding)
    except UnicodeDecodeError:
        try:
            # Î•Î½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ· Ï„Î·Ï‚ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î·Ï‚ Ï€ÏÎ¿ÏƒÎ´Î¹Î¿ÏÎ¹ÏƒÎ¼Î­Î½Î·Ï‚ ÎºÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ ÏƒÏ„Î· Î»Î¿Î³Î¹ÎºÎ® email
            return payload.decode("ISO-8859-1")
        except UnicodeDecodeError:
            print("None encoding found")
            # Fallback: Î±Î³Î½ÏŒÎ·ÏƒÎµ Î¼Î· Î­Î³ÎºÏ…ÏÎ¿Ï…Ï‚ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚ Î³Î¹Î± Î½Î± Ï€ÏÎ¿Ï‡Ï‰ÏÎ®ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î·Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
            return payload.decode("utf-8", errors="ignore")


def extend_df_with_columns(df):
    """
    Î•Ï€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Ï„Î¿ DataFrame:
    - Î•Î¾Î¬Î³ÎµÎ¹ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Ï„Î· ÏƒÏ„Î®Î»Î· `Body` Î³Î¹Î± `Port`, `Public IP`, `Time`, ÎºÎ±Î¹ `Api`.
    - ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ Ï„Î· ÏƒÏ„Î®Î»Î· `Time` ÏƒÎµ `Date` (2025.30.01) ÎºÎ±Î¹ `Time` (15:03:38).
    - Î”Î¹Î±Î³ÏÎ¬Ï†ÎµÎ¹ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ `Subject` ÎºÎ±Î¹ `From`, ÎºÎ±Î¹ Î±Ï†Î±Î¹ÏÎµÎ¯ Ï„Î· ÏƒÏ„Î®Î»Î· `Body`.
    """

    # ÎšÎ±Î½Î¿Î½Î¹ÎºÎ­Ï‚ ÎµÎºÏ†ÏÎ¬ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    data_patterns = {
        "Port": r"Port:\s*(\d+)",
        "Public IP": r"Public IP:\s*([\d.]+)",
        "Time": r"Time:\s*([\d:]+\s\w+\s[\w/]+)",
        "Api": r"Api:\s*(.+)",
    }

    # Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± ÎµÎ¾Î±Î³Ï‰Î³Î® Ï„Î¹Î¼ÏÎ½ Î±Ï€ÏŒ Ï„Î¿ body ÎµÎ½ÏŒÏ‚ email
    def extract_value_from_body(body, pattern):
        match = re.search(pattern, body)
        return match.group(1).strip() if match else None

    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î½Î­Ï‰Î½ ÏƒÏ„Î·Î»ÏÎ½ ÏƒÏ„Î¿ DataFrame
    for key, pattern in data_patterns.items():
        df[key] = df["Body"].apply(lambda body: extract_value_from_body(body, pattern))

    # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÎºÎ±Î¹ Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î® `Time` ÏƒÎµ Î´ÏÎ¿ Î½Î­ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚ `Date` ÎºÎ±Î¹ `Time`
    def split_time_column(value):
        if value and " on " in value:
            try:
                # Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Time ÎºÎ±Î¹ Date
                time_part, date_part = value.split(" on ")
                # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï„Î¿Ï… date_part (Ï€.Ï‡. "jan/30/2025") ÏƒÏ„Î· Î¼Î¿ÏÏ†Î® 2025.30.01
                date_obj = datetime.strptime(date_part, "%b/%d/%Y")
                formatted_date = date_obj.strftime("%Y.%d.%m")
                return pd.Series({"Time": time_part.strip(), "Date": formatted_date})
            except Exception as e:
                print(f"Error parsing date/time: {value}. Error: {e}")
        return pd.Series({"Time": None, "Date": None})

    # Î‘Î½Î¬Î»Ï…ÏƒÎ· Time ÏƒÎµ Î´ÏÎ¿ ÏƒÏ„Î®Î»ÎµÏ‚ - Date ÎºÎ±Î¹ Time
    df[["Time", "Date"]] = df["Time"].apply(split_time_column)

    # Î‘Ï†Î±Î¹ÏÎµÎ¯ Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚ `\r` Î±Ï€ÏŒ Ï„Î· ÏƒÏ„Î®Î»Î· `Api`
    df["Api"] = df["Api"].str.replace("\r", "", regex=False)

    # Î”Î¹Î±Î³ÏÎ±Ï†Î® Ï€ÎµÏÎ¹Ï„Ï„ÏÎ½ ÏƒÏ„Î·Î»ÏÎ½
    df.drop(columns=["Subject", "From", "Body"], inplace=True)

    # Î•Ï€Î±Î½Î±Ï„Î±Î¾Î¹Î½ÏŒÎ¼Î·ÏƒÎ· ÏƒÏ„Î·Î»ÏÎ½ ÏŒÏ€Ï‰Ï‚ Î¶Î·Ï„Î®Î¸Î·ÎºÎµ
    df = df[["Port", "Public IP", "Date", "Time", "Api"]]

    return df


def retrieve_mikrotik_emails(_mail, label, counter_file="counter.txt"):
    try:
        # Î•Ï€Î¹Î»Î¿Î³Î® Ï†Î±ÎºÎ­Î»Î¿Ï…
        status, messages = _mail.select(label)
        if status != "OK":
            raise ValueError(
                f"Failed to select folder/label '{label}'. Please ensure it exists."
            )

        # Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· Î® Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… counter.txt
        if not os.path.exists(counter_file):
            # Î‘Î½ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹, Ï„Î¿ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î¼Îµ Î±ÏÏ‡Î¹ÎºÎ® Ï„Î¹Î¼Î® "0"
            with open(counter_file, "w") as f:
                f.write("0")
            last_read_email_count = 0
        else:
            # Î‘Î½ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹, Î´Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î·Î½ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î± ÎºÎ±Ï„Î±Î¼Î­Ï„ÏÎ·ÏƒÎ·
            with open(counter_file, "r") as f:
                last_read_email_count = int(f.read().strip())

        # Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ emails Î¼Îµ Ï„Î¿ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿ Î¸Î­Î¼Î±
        status, messages = _mail.search(None, '(SUBJECT "MikroTik Alert:")')
        if status != "OK":
            raise RuntimeError("Failed to execute SEARCH command.")

        email_ids = messages[0].split()
        total_emails = len(email_ids)

        # Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î½Î­Î± emails
        if last_read_email_count >= total_emails:
            print("No new emails to process.", end="")
            return None  # ÎšÎ±Î¼Î¯Î± Î½Î­Î± ÎµÎ³Î³ÏÎ±Ï†Î®

        # Î›Î¯ÏƒÏ„Î± Î³Î¹Î± Ï„Î·Î½ Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ email
        email_data = []

        # Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î¼ÏŒÎ½Î¿ Ï„Ï‰Î½ Î½Î­Ï‰Î½ emails
        for email_id in tqdm(email_ids[last_read_email_count:]):
            # Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· email
            status, msg_data = _mail.fetch(email_id, "(RFC822)")
            for response_part in msg_data:
                if isinstance(response_part, tuple):
                    # Î‘Ï€Î¿ÎºÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î¿Ï… email
                    msg = email.message_from_bytes(response_part[1])

                    subject = decode_header(msg["Subject"])[0][0]
                    if isinstance(subject, bytes):
                        subject = subject.decode()  # Î‘Ï€Î¿ÎºÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Î½ ÎµÎ¯Î½Î±Î¹ bytes
                    from_ = msg.get("From")

                    # Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· ÏƒÏÎ¼Î±Ï„Î¿Ï‚ email
                    body = ""
                    if msg.is_multipart():
                        for part in msg.walk():
                            content_type = part.get_content_type()
                            content_disposition = str(part.get("Content-Disposition"))

                            if (
                                    content_type == "text/plain"
                                    and "attachment" not in content_disposition
                            ):
                                # Î‘Ï€ÏŒÎºÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï€ÎµÏÎ¹ÎµÏ‡Î¿Î¼Î­Î½Î¿Ï… ÎºÎ±Î¹ Î±ÏƒÏ†Î±Î»Î®Ï‚ Î±Ï€Î¿ÎºÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·
                                body = decode_safe(part.get_payload(decode=True))
                                break
                    else:
                        # ÎœÎ·-Ï€Î¿Î»Ï…Î¼ÎµÏÎ­Ï‚ Î¼Î®Î½Ï…Î¼Î± (Î±Ï€Î»ÏŒ ÏƒÏÎ¼Î±)
                        body = decode_safe(msg.get_payload(decode=True))

                    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î· Î»Î¯ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
                    email_data.append({"Subject": subject, "From": from_, "Body": body})

        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÏƒÎµ pandas DataFrame
        new_df = pd.DataFrame(email_data)

        # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… ÎºÎ±Ï„Î±Î¼Î­Ï„ÏÎ·ÏƒÎ·Ï‚ emails
        with open(counter_file, "w") as f:
            f.write(str(total_emails))

        return new_df  # Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Ï„Î¿Ï… DataFrame Î¼Îµ Ï„Î± Î½Î­Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±

    except Exception as e:
        print(f"Error while fetching emails: {e}", end="")
        return None  # Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® None ÏƒÎµ Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ· ÏƒÏ†Î¬Î»Î¼Î±Ï„Î¿Ï‚


def run(csv_file="emails_data.csv"):
    # Î£ÏÎ½Î´ÎµÏƒÎ· ÏƒÏ„Î¿ Gmail
    mail = connect_to_gmail()
    if mail:
        # Î•Î»Î­Î³Ï‡Î¿Ï…Î¼Îµ Î³Î¹Î± Î½Î­Î± emails
        new_emails_df = retrieve_mikrotik_emails(mail,
                                                 label="MIKROTIK")  # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¿ 'INBOX' Î® Ï„Î¿ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿ label
        mail.logout()

        if new_emails_df is not None:
            print("New emails fetched. Processing...", end="")

            # Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
            new_emails_df = extend_df_with_columns(new_emails_df)

            if os.path.exists(csv_file):
                print(f"CSV file {csv_file} exists. Appending data...", end="")
                # Î”Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î± Ï…Ï€Î¬ÏÏ‡Î¿Î½Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
                try:
                    existing_df = pd.read_csv(csv_file)
                    # Î£Ï…Î³Ï‡ÏÎ½ÎµÏ…ÏƒÎ· Ï‡Ï‰ÏÎ¯Ï‚ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±
                    combined_df = (
                        pd.concat([existing_df, new_emails_df])
                        .drop_duplicates()
                        .reset_index(drop=True)
                    )
                except Exception as e:
                    combined_df = new_emails_df

            else:
                print(f"CSV file {csv_file} does not exist. Creating...", end="")
                combined_df = new_emails_df

            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ…Î³Ï‡Ï‰Î½ÎµÏ…Î¼Î­Î½Î¿Ï… DataFrame ÏƒÏ„Î¿ CSV
            combined_df.to_csv(csv_file, index=False)
            return combined_df

        else:
            print("No new emails. Loading data from CSV...", end="")
            # Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î½Î­Î± emails, Î´Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ Î±Ï€ÏŒ Ï„Î¿ CSV (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹)
            if os.path.exists(csv_file):
                return pd.read_csv(csv_file)
            else:
                print(f"CSV file {csv_file} does not exist. Returning empty DataFrame.", end="")
                return pd.DataFrame()


def plot_run(df, path, sankey_path, line_path, color, loop_counter):
    data_analysis.visualize_api_hackers_ports_donut(df, path_a=path, color=color)
    data_analysis.time_series_analysis(df, path_a=line_path, loop_counter=loop_counter)
    data_analysis.sankey_graph(loop_counter, df, path_a=sankey_path)
